{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef46072-e749-4f82-b80b-6628a310be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.12/site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "021e0876-1037-4ca7-9ff1-596ba73048c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/users/lokeshthangavel/documents/loki coding/sure ride/namma_yatri_imbalanced_dataset_stronger_correlations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa7dfffb-165f-4956-b972-e62f9ebb243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0549179c-d494-42ce-87ef-2b9308e93281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_type                  0.289498\n",
      "weather_condition             0.167481\n",
      "distance_to_pickup_km         0.161526\n",
      "estimated_trip_distance_km    0.104265\n",
      "traffic_congestion_level      0.062580\n",
      "driver_experience_months      0.053029\n",
      "hour_of_day                   0.041066\n",
      "day_of_week                   0.037989\n",
      "fare_amount                   0.026741\n",
      "hours_already_worked          0.022367\n",
      "is_peak_hour                  0.021116\n",
      "historical_acceptance_rate    0.006584\n",
      "estimated_trip_time_min       0.005759\n",
      "driver_earnings               0.000000\n",
      "day                           0.000000\n",
      "vehicle_quality               0.000000\n",
      "month                         0.000000\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/users/lokeshthangavel/documents/loki coding/sure ride/namma_yatri_imbalanced_dataset_stronger_correlations.csv\")\n",
    "\n",
    "# Function to handle outliers using IQR\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df[column] = np.clip(df[column], lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "# Handle outliers in numerical columns\n",
    "outlier_cols = [\n",
    "    \"distance_to_pickup_km\",\n",
    "    \"estimated_trip_distance_km\",\n",
    "    \"estimated_trip_time_min\",\n",
    "    \"hours_already_worked\",\n",
    "    \"fare_amount\",\n",
    "    \"driver_earnings\",\n",
    "]\n",
    "for col in outlier_cols:\n",
    "    df = remove_outliers_iqr(df, col)\n",
    "\n",
    "# Drop non-numeric columns\n",
    "columns_to_drop = [\"driver_id\", \"timestamp\", \"preferred_areas\"]\n",
    "df_cleaned = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = [\"service_type\", \"vehicle_quality\", \"weather_condition\"]\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Convert 'traffic_congestion_level' to numerical if needed\n",
    "if df_cleaned[\"traffic_congestion_level\"].dtype == \"object\":\n",
    "    df_cleaned[\"traffic_congestion_level\"] = LabelEncoder().fit_transform(df_cleaned[\"traffic_congestion_level\"])\n",
    "\n",
    "# Sample dataset for faster training\n",
    "df_sampled = df_cleaned.sample(n=20000, random_state=42)\n",
    "\n",
    "# Define features and target\n",
    "X = df_sampled.drop(columns=[\"acceptance_probability\", \"accepted_ride\"], errors='ignore')\n",
    "y = df_sampled[\"acceptance_probability\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model with reduced depth\n",
    "xgb_model = XGBRegressor(n_estimators=30, max_depth=4, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc5a8212-a27b-4c46-a4a8-1333e893bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['driver_id', 'timestamp', 'month', 'day', 'hour_of_day', 'day_of_week',\n",
      "       'is_peak_hour', 'service_type', 'driver_experience_months',\n",
      "       'vehicle_quality', 'preferred_areas', 'historical_acceptance_rate',\n",
      "       'distance_to_pickup_km', 'estimated_trip_distance_km',\n",
      "       'estimated_trip_time_min', 'fare_amount', 'driver_earnings',\n",
      "       'weather_condition', 'traffic_congestion_level', 'hours_already_worked',\n",
      "       'acceptance_probability', 'accepted_ride'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/users/lokeshthangavel/documents/loki coding/sure ride/namma_yatri_imbalanced_dataset_stronger_correlations.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a91fce7-4d28-44b9-b74a-471674f12d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.60      1195\n",
      "           1       0.93      0.98      0.96      8805\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.85      0.74      0.78     10000\n",
      "weighted avg       0.91      0.92      0.91     10000\n",
      "\n",
      "       service_type  weather_condition  distance_to_pickup_km  \\\n",
      "33553             0                  3              -0.948499   \n",
      "9427              0                  2               1.108486   \n",
      "199               0                  1               0.139220   \n",
      "12447             0                  2               1.536984   \n",
      "39489             0                  0               1.259470   \n",
      "42724             0                  2              -0.822355   \n",
      "10822             0                  0              -0.561601   \n",
      "49498             0                  0              -0.521733   \n",
      "4144              0                  2              -0.464637   \n",
      "36958             1                  0              -0.691277   \n",
      "\n",
      "       estimated_trip_distance_km  traffic_congestion_level  \\\n",
      "33553                    0.273602                         2   \n",
      "9427                    -0.327186                         2   \n",
      "199                      0.523778                         1   \n",
      "12447                   -0.518710                         1   \n",
      "39489                    0.401853                         0   \n",
      "42724                    0.564888                         3   \n",
      "10822                    0.623878                         2   \n",
      "49498                    0.174797                         0   \n",
      "4144                    -0.067861                         1   \n",
      "36958                   -0.523711                         1   \n",
      "\n",
      "       predicted_acceptance_probability  actual_accepted  \n",
      "33553                          0.993403                1  \n",
      "9427                           0.852400                1  \n",
      "199                            0.990207                1  \n",
      "12447                          0.813858                0  \n",
      "39489                          0.982582                1  \n",
      "42724                          0.974620                1  \n",
      "10822                          0.993357                1  \n",
      "49498                          0.991671                1  \n",
      "4144                           0.973968                1  \n",
      "36958                          0.984978                1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/users/lokeshthangavel/documents/loki coding/sure ride/namma_yatri_imbalanced_dataset_stronger_correlations.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select relevant features\n",
    "important_features = [\n",
    "    \"service_type\", \"weather_condition\", \"distance_to_pickup_km\",\n",
    "    \"estimated_trip_distance_km\", \"traffic_congestion_level\"\n",
    "]\n",
    "\n",
    "target = \"accepted_ride\"\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = [\"service_type\", \"weather_condition\", \"traffic_congestion_level\"]\n",
    "\n",
    "# Apply Label Encoding to all categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le  # Store encoders for future decoding\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[[\"distance_to_pickup_km\", \"estimated_trip_distance_km\"]] = \\\n",
    "    scaler.fit_transform(df[[\"distance_to_pickup_km\", \"estimated_trip_distance_km\"]])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = df[important_features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Gradient Boosting Classifier\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "calibrated_gbm = CalibratedClassifierCV(gbm, method='sigmoid')\n",
    "calibrated_gbm.fit(X_train, y_train)\n",
    "\n",
    "# Predict acceptance probability\n",
    "y_proba = calibrated_gbm.predict_proba(X_test)[:, 1]  # Probability of acceptance\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = calibrated_gbm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save probabilities to dataframe\n",
    "df_test = X_test.copy()\n",
    "df_test[\"predicted_acceptance_probability\"] = y_proba\n",
    "df_test[\"actual_accepted\"] = y_test.values\n",
    "\n",
    "# Display sample predictions\n",
    "print(df_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0f5bc-438b-4d11-b786-342eaf27da9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
